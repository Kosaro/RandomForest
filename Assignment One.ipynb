{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "data/Madelon/madelon_train.data not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5b905f63c17b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-5b905f63c17b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Part (a) madelon decision trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# read in data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmadelon_training_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmadelon_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"madelon_train.data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mmadelon_training_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmadelon_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"madelon_train.labels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mmadelon_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmadelon_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"madelon_valid.data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[0;32m    979\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: data/Madelon/madelon_train.data not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "\n",
    "madelon_path = \"data/Madelon/\"\n",
    "wilt_path = \"data/wilt/\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Part (a) madelon decision trees\n",
    "    # read in data\n",
    "    madelon_training_data = np.loadtxt(madelon_path + \"madelon_train.data\")\n",
    "    madelon_training_labels = np.loadtxt(madelon_path + \"madelon_train.labels\")\n",
    "    madelon_test_data = np.loadtxt(madelon_path + \"madelon_valid.data\")\n",
    "    madelon_test_labels = np.loadtxt(madelon_path + \"madelon_valid.labels\")\n",
    "    # train the trees on the data\n",
    "    madelon_trees = train_trees(madelon_training_data, madelon_training_labels, 12)\n",
    "    # calculate error\n",
    "    madelon_training_error = [1 - tree.score(madelon_training_data, madelon_training_labels) for tree in madelon_trees]\n",
    "    madelon_test_error = [1 - tree.score(madelon_test_data, madelon_test_labels) for tree in madelon_trees]\n",
    "    # graph error\n",
    "    plot_error(np.arange(1, 13), madelon_training_error, madelon_test_error, \"Madelon Error\", add_tree_table)\n",
    "\n",
    "    # Part (b) wilt decision trees\n",
    "    # read in data\n",
    "    wilt_train_data = np.loadtxt(wilt_path + \"wilt_train.csv\", delimiter=\",\")\n",
    "    wilt_train_labels = np.loadtxt(wilt_path + \"wilt_train.labels\")\n",
    "    wilt_test_data = np.loadtxt(wilt_path + \"wilt_test.csv\", delimiter=\",\")\n",
    "    wilt_test_labels = np.loadtxt(wilt_path + \"wilt_test.labels\")\n",
    "    # train the trees on the data\n",
    "    wilt_trees = train_trees(wilt_train_data, wilt_train_labels, 10)\n",
    "    # calculate error\n",
    "    wilt_training_error = [1 - tree.score(wilt_train_data, wilt_train_labels) for tree in wilt_trees]\n",
    "    wilt_test_error = [1 - tree.score(wilt_test_data, wilt_test_labels) for tree in wilt_trees]\n",
    "    # graph error\n",
    "    plot_error(np.arange(1, 11), wilt_training_error, wilt_test_error, \"Wilt Error\", add_tree_table)\n",
    "\n",
    "    # Part (c) madelon random forest with square root features\n",
    "    num_trees = (3, 10, 30, 100, 300)\n",
    "    forests_sqrt = train_forests(madelon_training_data, madelon_training_labels, num_trees, \"sqrt\")\n",
    "    # calculate error\n",
    "    forest_sqrt_training_error = [1 - forest.score(madelon_training_data, madelon_training_labels) for forest in forests_sqrt]\n",
    "    forest_sqrt_test_error = [1 - forest.score(madelon_test_data, madelon_test_labels) for forest in forests_sqrt]\n",
    "    # graph error\n",
    "    plot_error(num_trees, forest_sqrt_training_error, forest_sqrt_test_error, \"Random forest with square root features\", add_forest_table)\n",
    "\n",
    "    # Part (d) madelon random forest with natural log features\n",
    "    forests_ln = train_forests(madelon_training_data, madelon_training_labels, num_trees, round(math.log(500)))\n",
    "    # calculate error\n",
    "    forest_ln_training_error = [1 - forest.score(madelon_training_data, madelon_training_labels) for forest in forests_ln]\n",
    "    forest_ln_test_error = [1 - forest.score(madelon_test_data, madelon_test_labels) for forest in forests_ln]\n",
    "    # graph error\n",
    "    plot_error(num_trees, forest_ln_training_error, forest_ln_test_error, \"Random forest with natural log features\", add_forest_table)\n",
    "\n",
    "    # Part (e) madelon random forest with all features\n",
    "    forests_all = train_forests(madelon_training_data, madelon_training_labels, num_trees, None)\n",
    "    # calculate error\n",
    "    forest_all_training_error = [1 - forest.score(madelon_training_data, madelon_training_labels) for forest in forests_all]\n",
    "    forest_all_test_error = [1 - forest.score(madelon_test_data, madelon_test_labels) for forest in forests_all]\n",
    "    # graph error\n",
    "    plot_error(num_trees, forest_all_training_error, forest_all_test_error, \"Random forest with all features\", add_forest_table)\n",
    "\n",
    "\n",
    "def train_trees(training_data, training_labels, maximum_depth):\n",
    "    \"\"\"uses the data and labels to train a trees of depth of i to maximum_depth\n",
    "       and returns them in a list\"\"\"\n",
    "    decision_tree_list = []\n",
    "    # iterate from 1 to maximum_depth\n",
    "    for i in range(1, maximum_depth + 1):\n",
    "        decision_tree = DecisionTreeClassifier(max_depth=i)  # create new tree with depth i\n",
    "        decision_tree.fit(training_data, training_labels)  # train the tree\n",
    "        decision_tree_list.append(decision_tree)  # add tree to list\n",
    "    return decision_tree_list\n",
    "\n",
    "\n",
    "def train_forests(training_data, training_labels, num_trees, features):\n",
    "    \"\"\"uses the data and labels to train random forests of sizes dictated by num_trees\n",
    "       and returns them in a list\"\"\"\n",
    "    random_forest_list = []\n",
    "    # iterate from 1 to maximum_depth\n",
    "    for n in num_trees:\n",
    "        # create new forest with n trees and given number of features\n",
    "        random_forest = RandomForestClassifier(n_estimators=n, max_features=features)\n",
    "        random_forest.fit(training_data, training_labels)  # train the tree\n",
    "        random_forest_list.append(random_forest)  # add tree to list\n",
    "    return random_forest_list\n",
    "\n",
    "\n",
    "def add_tree_table(domain, training_error, test_error):\n",
    "    column_labels = [\"Minimum Error\", \"Depth\"]  # table column labels\n",
    "    row_labels = [\"Training\", \"Test\"]  # table row labels\n",
    "    min_error = min(training_error)  # minimum training error\n",
    "    training_row = [f\"{min_error:.3f}\", domain[training_error.index(min_error)]]  # set row data (min error, depth)\n",
    "    min_error = min(test_error)  # minimum testing error\n",
    "    test_row = [f\"{min_error:.3f}\", domain[test_error.index(min_error)]]  # set row data (min error, depth)\n",
    "\n",
    "    # create table\n",
    "    plt.table(cellText=[training_row, test_row], colLabels=column_labels, rowLabels=row_labels,\n",
    "              bbox=[.3, -.6, .4, .3])\n",
    "\n",
    "def add_forest_table(domain, training_error, test_error):\n",
    "    row_labels = [\"Number of trees\", \"Training error\", \"Test error\"]  # table row labels\n",
    "    table_entries = np.asarray([training_error, test_error])\n",
    "    table_entries = np.vectorize(lambda x : f\"{x:.3f}\")(table_entries)  # shorten to 3 decimal places\n",
    "    table_entries = np.vstack([domain, table_entries])  # add domain to entries\n",
    "    # create table\n",
    "    plt.table(cellText=table_entries, rowLabels=row_labels, bbox=[.2, -.6, .8, .3])\n",
    "\n",
    "def plot_error(domain, training_error, test_error, title, add_table=None):\n",
    "    \"\"\"graph the training error and the test error over the depth of the domain\"\"\"\n",
    "    plt.gcf().canvas.set_window_title(title)  # set window title\n",
    "    plt.title(title)  # set plot tithttp://localhost:8888/?token=232c66583c7593739f9d5a2fc5d97efdf4dc15a368fbada0le\n",
    "    plt.plot(domain, training_error, label=\"Training Error\")  # plot training error\n",
    "    plt.plot(domain, test_error, label=\"Test Error\")  # plot test error\n",
    "    plt.xlabel(\"Tree Depth\")  # set x label\n",
    "    plt.ylabel(\"Error\")  # set y label\n",
    "    plt.legend(loc=\"upper right\")  # add legend\n",
    "\n",
    "    if add_table is not None:\n",
    "        add_table(domain, training_error, test_error)\n",
    "\n",
    "    plt.tight_layout()  # set layout\n",
    "    plt.show()  # show figure\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
